[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "The Biology to be Explored in LLMs",
    "section": "",
    "text": "This post will be summarizing key points about molecular biology which I have learned from the article “Large Language Models in Molecular Biology” by Serafim Batzoglou.\nIn an attempt to further explore LLMs to prepare for my upcoming project regarding LLMs, the following summary of the biological information in the above article was generated by prompting ChatGPT and edited by me.\n\nCellular and Molecular Biology Components\n\nCentral Dogma\nThe central dogma of molecular biology explains how genetic information flows within living organisms. It states that DNA, which is housed in the nucleus of every cell, is the source of this genetic information. Human DNA consists of approximately 3 billion nucleotides organized into 23 chromosomes, with 22 being autosomes and one being a sex chromosome (X or Y). Each person inherits two nearly identical copies of the human genome, one from each parent. The genetic material from both parents is retained in the nucleus of each of the roughly 30 trillion cells in the human body. The genome contains about 20,000 genes responsible for protein synthesis, with only about 1% of the genome coding for proteins. The remaining portions of the genome include regions that control gene expression, regions within genes that do not code for proteins, regions contributing to DNA structure, and “junk” regions of self-replicating DNA.\nProtein synthesis, a fundamental process in molecular biology, involves three main steps: transcription, splicing, and translation. During transcription, a DNA segment serving as a gene template is copied into messenger RNA (mRNA). The mRNA molecule undergoes splicing, where certain segments, called introns, are removed, and the remaining segments, called exons, are joined together to form mature mRNA. Splicing is crucial in higher organisms because it allows a single gene to produce multiple protein variants by assembling different combinations of exons. The mRNA is then transported to the ribosome, where translation occurs. During translation, the mRNA sequence is decoded into amino acids, which are the building blocks of proteins. These amino acids are linked together to form a protein sequence, which folds into a functional three-dimensional structure. Proteins play essential roles in various biological processes, providing structural components, catalyzing reactions as enzymes, and facilitating communication and transportation within cells.\n\n\nGene Regulation\nGene regulation is a complex process that controls when, where, and in what quantity genes are expressed in cells. It ensures the timely production of the right proteins in appropriate amounts. Gene regulation occurs at different levels, involving chromatin structure, chemical modifications, and the action of transcription factors. Transcription factors are proteins that bind to specific DNA sequences and influence the recruitment of RNA polymerase, the enzyme responsible for mRNA synthesis. They help regulate the expression of target genes to ensure they are appropriately expressed in response to signals.\nPromoters and enhancers are DNA regions that contribute to gene expression control, with promoters located adjacent to gene starts and enhancers situated within introns or between genes, further downstream in the DNA. Chromatin structure, formed by DNA wrapping around histone proteins, determines which DNA regions are accessible for gene expression. Chemical modifications of histones and DNA, such as acetylation, methylation, and DNA methylation, can influence chromatin structure and gene expression. Gene regulation is specific to each type of cell - some cells have certain genes expressed while other cells have different genes expressed. This is what allows cells to have specialized functions.\nThe flow of genetic information is traditionally described as unidirectional: DNA to RNA to protein. However, there are exceptions to this rule. Reverse transcription allows RNA to be converted back into DNA, as seen in retroviruses like HIV. DNA can also be transcribed into different types of RNA, such as transfer RNA (tRNA) and ribosomal RNA (rRNA), adding complexity to genetic information flow.\n\n\nEpigenetic Mechanisms\nEpigenetic mechanisms, including DNA methylation and histone modifications, play a role in gene regulation and can be inherited. DNA methylation is a chemical modification where methyl is added to the DNA molecule, usually at specific cytosine bases. Methylation influences gene expression by affecting the binding of transcription factors and the chromatin structure. Chromatin must be unfolded for gene expression, so by making the chromatin more compact, methylation makes transcription more difficult (affects gene accessibility).\nDNA variation contributes to the diversity and heritability of traits among individuals. DNA variants are introduced primarily through mutations between the genomes of parents and germline genomes passed on to offspring. Deleterious variants tend to be eliminated from the population over time through natural selection. Genetic variations common in humans are typically benign or contribute to diseases that manifest later in life. Some rare mutations can affect the splicing sites (the boundaries where genes are spliced). As a result, they can cause the production of a completely different protein sequence, thus different protein function. This is why they contribute to 10% of rare genetic diseases.\nSo, predicting splice sites and determining gene structure is important to diagnose genetic diseases."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Basics of LLMs and Their Role in the Field of Biology",
    "section": "",
    "text": "Computational Components (LLMs)\n\nWhat is an LLM?\nA Large Language Model is a type of neural network which uses vast amounts of textual data in order to generate text composed of human language. By identifying patterns and context within the text which is inputted, it is able to respond to questions, create new content, and even make predictions.\n\n\nWhat are the different types of LLMs?\n\nWord grams: These are rudimentary models that predict the next word based on the frequency of word pairs or word bags in the training data. They DO NOT consider context or word order, resulting in less coherent predictions. Text generated using word grams often lacks resemblance to human text.\nCNNs (Convolutional Neural Networks): CNN models analyze text by considering relationships between adjacent words within a fixed window. They can have wide windows using techniques like dilation. While CNNs are good at identifying local patterns, they struggle with capturing long-range dependencies and comprehending complex sentence structures.\nLSTMs (Long Short-Term Memory networks): LSTMs are a variant of Recurrent Neural Networks (RNNs) capable of storing and processing information from earlier parts of a text. They outperform CNNs in understanding context and managing long-range dependencies. However, they still face challenges with complex sentences and long text.\nAttention Mechanisms: Attention mechanisms are not models in themselves, but mechanisms. They allow models to focus on relevant parts of the input when making predictions. These models have multiple attention “heads” that can concentrate on different parts of the previous text. Transformers, a class of language models, implement attention mechanisms.\nLarge Language Models (LLMs): LLMs, such as GPT-3, are transformers trained on vast amounts of data. Their large size facilitates the learning of intricate patterns, relationships, and context within the text. LLMs represent the most advanced language models available and can generate accurate and coherent responses across a wide range of topics.\n\nThe following LLMs use transformer architecture and were breakthroughs in the field:\n\nBERT (Bidirectional Encoder Representations from Transformers): BERT is a series of LLMs introduced by Google. It is trained using masked language modeling and next sentence prediction. BERT understands context from both the left and right sides of the input, making it bidirectional. It has been open-sourced and achieved significant advancements in language understanding.\nGPT (Generative Pretrained Transformer): GPT is a series of LLMs introduced by OpenAI. Unlike BERT, GPT is trained using the traditional language modeling task of autocompletion. It attends only to the left context during training, making it unidirectional. GPT excels in tasks involving text generation and has shown remarkable performance across various domains.\n\nThese types of LLMs vary in their modeling capabilities, with LSTMs and transformers like BERT and GPT being more advanced in understanding context and generating coherent responses. LLMs have significantly evolved, and the latest generation, such as GPT-4, exhibits promising signs of general intelligence.\n\n\nWhat about Data Generation for LLMs for Use in Genetics?\nAdvances in DNA sequencing have allowed us to fully sequence the entire human genome for less than $200. Sequencing-based methods have significantly advanced our ability to measure molecular function. These methods allow for the exposure of crucial molecular information such as chromatin structure, histone modifications, and transcription factor binding to DNA. Short DNA segments with specific properties of interest are isolated and sequenced in experiments to obtain this information. The rapid progress in DNA sequencing technology has outpaced Moore’s law and enabled the measurement of various genetic aspects within biological samples, including gene expression, chromatin accessibility, and histone modifications, often with single-cell or spatial precision.\n\n\nUsing LLMs for Diagnosing Genetic Diseases\nAs mentioned in an earlier post, mutations at splicing sites can completely change which proteins are produced, thus the protein function, resulting in rare genetic diseases. However, using LLMs, predicting splice sites and deducing gene structure becomes simpler and contribute to the diagnosis of rare genetic diseases.\nSpliceAI is a deep residual Convolutional Neural Network (CNN) introduced by the Illumina AI laboratory. It operates by utilizing earlier techniques for language modeling applied to DNA sequences, rather than functioning as a Language Model itself. Its primary purpose is to accurately predict the locations of intron-exon boundaries in the human genome, specifically the donor and acceptor sites. SpliceAI achieved a high precision-recall area under the curve (PR-AUC) score of 0.98, surpassing the previous best score of 0.23.\nOne key feature of SpliceAI is its ability to perform in silico mutational analysis. It can artificially modify DNA positions and determine whether the alterations introduce or eliminate splice sites within 10,000 nucleotides of the mutation. This capability makes SpliceAI valuable for aiding genetic diagnosis, particularly in cases of rare undiagnosed pediatric diseases. By inputting variants of a patient’s DNA into SpliceAI, it can assess the likelihood of altering gene splicing and disrupting gene function. SpliceAI’s high accuracy stems from its deep residual network’s capacity to learn complex biomolecular properties of DNA sequences that guide the splicing machinery to the correct splice sites. It captures and utilizes these previously unknown or imprecisely known properties effectively.\n\n\nPredicting Gene Expression from a DNA Sequence Using LLMs\n\nEnformer is a transformer-based tool and a part of the lineage of language models designed to predict cell type-specific gene expression levels based on the DNA sequence near a gene. It is trained using supervised learning to predict various experimental data types for a given genome region, including chromatin status, histone modifications, transcription factor binding, and gene expression levels. By incorporating attention mechanisms, Enformer can effectively capture correlations between molecular entities across distant regions up to 100,000 nucleotides away.\nWhile Enformer performs reasonably well in predicting gene expression from sequence alone, it currently falls short compared to experimental replicates, correlating at a level of 0.85, with a three-fold higher error rate. However, as more data are incorporated and the model is improved, its performance is expected to enhance. Enformer can also predict changes in gene expression caused by mutations in different individuals and artificially introduced mutations through CRISPR experiments. However, it has limitations in predicting the effects of distal enhancers and determining the direction of the impact of personal variants on gene expression, likely due to insufficient training data.\n\n\n\nEnformers for effective gene expression prediction. Credit: Erik Storrs blog.\n\n\n\n\nFoundation Models\nFoundation models, such as the transformer-based GPT models, are large deep learning architectures that encode a vast amount of knowledge from various sources. They can be fine-tuned for specific tasks, resulting in high-performance systems for different applications. Two recent preprint models in molecular biology are introduced: scGPT and Nucleotide Transformer.\nscGPT is designed for single-cell transcriptomics, chromatin accessibility, and protein abundance. It is trained on single-cell data from 10 million human cells and learns embeddings that provide insights into cellular states and biological pathways. The model is trained to generate data based on gene prompts and cell prompts, predicting genes and their confidence values. scGPT is then fine-tuned for tasks like batch correction, cell annotation, perturbation prediction, multiomics, and pathway prediction.\nNucleotide Transformer focuses on raw DNA sequences and uses the BERT methodology. It tokenizes sequences into k-mers of length 6 and is trained on the reference human genome, diverse human genomes, and genomes of other species. It is applied to 18 downstream tasks, including promoter prediction, splice site prediction, and histone modifications. Predictions are made through probing or computationally inexpensive fine-tuning.\n\n\nWhat the AI Actually Does: Training LLMs in Predicting Gene Expression\nTeach it one-step causality relationships: “if a certain mutation occurs, a specific gene malfunctions. If this gene is under-expressed, other genes in the cascade increase or decrease” (Batzoglou). Ultimately, we want it to learn the complex statistical properties of existing biological systems. Batzoglou states that it can be “learned from triangulating between correlations across modalities such as DNA variation, protein abundance and phenotype (a technique known as Mendelian randomization)”.\nIn all, the deep learning technology is strong enough at this point to take in genomic data and output predictions for gene expression or other biological information. These technologies are continuously being developed, becoming even more powerful, efficient, and precise day-by-day."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My ‘LLM in Biology’ Blog!",
    "section": "",
    "text": "This is the introductory post about the blog!\n\n\n\nCredit: Serafim Batzoglou, “Large Language Models in Biology”. Image from the author, created by Midjourney, prompted by “DNA”.\n\n\nThis blog will ultimately track my progress in learning about Large Language Models (LLMs) and their applications in molecular biology throughout the course of my 8-week program in the Im Lab at the University of Chicago. As I continue to learn biological knowledge and computational skills, I will continue to update this blog with what I have learned."
  },
  {
    "objectID": "posts/command-line-skills/index.html",
    "href": "posts/command-line-skills/index.html",
    "title": "Practicing Working with Terminal",
    "section": "",
    "text": "Working with Terminal ( + GitHub & VSCode)\nThe goal of this 8 week program is to be able to train an LLM to take in a full DNA sequence and predict some biological mechanism, such as gene expression or the effect of transcription factor binding. This can only be accomplished by using a supercomputer with many, many GPUs. These supercomputers will take in the training code from the terminal (or VSCode), which is why it is necessary to learn how to use VSCode and navigate the command line on the terminal of the laptop.\nFirst, you need to ensure that your new file that you are working on is in the correct environment. An environment is kind of like a storage area on your laptop for all your programming tools (e.g. Python)– it’s basically like a folder for everything you need.\nConda: Conda is an environment management tool which ensures that all your code, program, and files for a specific project are in the same environment. It also manages the installation, updating, and removal of packages (e.g. numpy, pandas, etc.). Conda comes with Anaconda and Miniconda, which you can download from the internet and have all the tools you would need to explore, model, and visualize datasets and more.\n\nMake a New Environment\nOpen terminal. Type the following, where “envname” is what you want to call your new environment:\nconda create —name envname\n\n\nActivate Newly Created Environment\nDo this to enter your desired environment. Type the following, where “envname” is your environment name:\nconda activate envname\n\n\nInstalling Tools for Programming in Python within New Environment\nType the following:\nconda install python\n\n\nInstall “pip” before installing packages for Python\npip is is a package management system used to install and manage software packages written in Python. It is a command-line tool that comes bundled with Python installations.\nTo install pip:\nconda install pip\nNote: Make sure you are in the desired environment while doing this.\nYou can check that you are in that desired environment if the environment name is in the parenthesis before the remaining line of code produced by terminal. So, after you activate the environment, it should produce something like this:\n(envname) Your-MacBook-Pro:~ macusername$\nWhen you are in the “normal” default environment, it will look something like this:\n(base) Your-MacBook-Pro:~ macusername$\n\n\nVarious pip commands\nHere are some commonly used pip commands:\n\npip install package_name: Installs a package from PyPI or another source.\n\n**For example, for installing numpy: python -m pip install numpy\nNote: The -m flag is commonly used for running Python scripts that are part of a package or when you want to ensure that the module is executed with the correct environment and dependencies.\n\npip uninstall package_name: Uninstalls a package.\npip list: Lists installed packages.\npip search package_name: Searches PyPI for packages matching the given name.\npip show package_name: Displays information about a specific package.\npip freeze: Generates a requirements.txt file containing a list of installed packages and their versions.\n\n\n\nUsing VSCode with Desired Environment\nVSCode has an integrated terminal that allows you to run commands directly within the editor. However, VSCode’s integrated terminal supports various shells, including PowerShell, Command Prompt (Windows), and Bash (macOS/Linux). So, while coding in VSCode, you need to make sure your code file is in the correct environment for your project. To do this, click on the bottom right of the screen on VSCode (in this example, the tab that says “3.11.3 (‘dlgtools’:conda). dlgtools is the name of my desired project environment. If the name of the environment is not the environment you want to work in, simply click on it and VSCode should open a tab at the top of your screen which says”Select Interpreter” and you can switch into a different environment. Your file will then be stored in this environment, so any packages or programs (like Python) which you plan to use in that file should be in that environment.\n\n\n\nChecking to See If You Have Python\nOnce the terminal is open, type python --version or python3 --version and press Enter.\n\nIf Python is installed, the command will display the version number of Python installed on your system. For example, you might see something like Python 3.9.2.\nIf Python is not installed or if the command is not recognized, you will typically see an error message indicating that the command is not found or recognized. In this case, you’ll need to install Python.\n\n\n\nChecking Your VSCode in Terminal\nIt is usually very difficult to see the output of your code in the integrated terminal of VSCode because it is kind of obscured among the lines about your system, device username, etc. To more clearly see the outputs of your code, you can do the following options:\n\nCheck the code outputs directly in your device’s terminal.\n\n\nOpen terminal.\nMaking sure you are in the desired environment (check the parenthesis), type the following, where file_name is the name of the VSCode file you want to check the code for:\nfrom file_name import *\nThis should clearly produce all the outputs for your code\n\n\nCopy-paste the code into Jupyter Notebook, Google Colab, or some other software with all the packages and tools built in and run the code.\nAdd the following line of code at the very top and very bottom of your coding file to create some space between the outputs within the integrated terminal of VSCode itself. This may not be as helpful to clearly see the code, but it may make a slight difference in visibility.\n\n\nprint(“\\n \\n \\n --------------- \\n \\n \\n”)\n\n\n\n\nFile Navigation in Terminal\nHere are some basic commands in your device’s terminal to make sure you are storing all your files within the desired directory. A directory is basically a type of folder on your device. You need to know which directory you are putting your project files so that you do not lose any important files in the short or long-term.\n\n\nAdditional Navigation Commands in Terminal:\nopen . → opens the directory you are currently in\ncd .. → goes to the parent directory (“steps back”)\nls -a → see all files within the directory (including hidden ones with .git)\ncd \\ → goes to the root directory of the hardware system (the furthest back root)\nBasically, I would start by typing “pwd” in Terminal to determine which directory I am currently in. If you need to move back into an earlier parent folder/directory, type cd ..\nIf you want to move into a further directory, type cd directory_name.\nIf you do not know the name of the directory you want to move further into, or if you do not know if that directory is within your current working directory, type ls to see all directories/files within your current working directory.\nls-a shows all the hidden files as well. Hidden files are files which work in the background of your project, and will begin with a . , which as .git or .nojekyll.\nAfter navigating into the root directory using cd \\, and then going into the desired directory, you can type “echo $PATH” to get the path to get to that directory.\n\n\n\nGithub/Git Commands in Terminal\n\nCloning on GitHub\nCloning refers to creating a local copy of an entire repository, including all its files, commit history, branches, and configuration. When you clone a repository, you create an identical copy on your local machine. This allows you to work with the project, make changes, commit them, and push them back to the remote repository. Cloning is typically used when you want to contribute to a project or work on your own project locally.\nTo clone a repository from GitHub, follow these steps:\n\nOpen the GitHub repository page in your web browser.\nClick on the “Code” button, located near the top-right corner of the repository page.\nClick on the clipboard icon to copy the repository’s URL. Alternatively, you can click on the “Download ZIP” button to download a compressed version of the repository instead of cloning it with Git.\nOpen your terminal or Git Bash (if you’re on Windows).\nNavigate to the directory where you want to clone the repository. You can use the cd command to change directories.\nOnce you’re in the desired directory, use the following command to clone the repository:\n\ngit clone &lt;paste_repository_URL&gt;\n\n\nAfter making changes to local files on your device, you want to sync those changes to the remote, master directory on Github. Git is a tools which allows this syncing. Carry out the following steps to do so:\n\ngit add * → add your changes\ngit status → check you are adding the files/directories you want\ngit commit -m ‘message’ → add a message\ngit push → update the master directory with your work\n\n\n\nAnother option – “pulling” in Github:\nPulling is the opposite of pushing: it’s what you do when the remote, master directory (maybe owned by someone other than you) has changes and you want to update your local directory with those changes. Typically used in collaborative files.\n\ngit pull → update your local directory with the master (remote) directory\n\n\n\nWhen would you pull?\nThe `git pull` command is used to update your local repository with the latest changes from a remote repository, typically the one you cloned from. It incorporates changes made by others and brings your local copy up to date.\nYou would use `git pull` in a few different scenarios:\n1. **Working on a shared project**: If you are collaborating with other people on a project, they might have made changes to the remote repository that you want to sync with. Running `git pull` will fetch those changes and merge them into your local branch.\n2. **Staying up to date**: Even if you’re not collaborating with others, it’s good practice to regularly update your local repository with the latest changes from the remote repository. This ensures that you have the most recent version of the code and can avoid conflicts when you eventually push your own changes.\n3. **Resolving conflicts**: Sometimes, when you pull changes from the remote repository, there might be conflicts between your local changes and the incoming changes. For example, if someone edited the same lines which you edited, and now there are different versions of the same file in the repo. In such cases, Git will notify you of the conflicts and provide an opportunity to resolve them manually.\nIt’s important to note that before running `git pull`, you should commit your local changes to avoid conflicts. If you have uncommitted changes, Git may ask you to stash or commit them before pulling.\n\n\nForking in Github:\nForking a file in GitHub is like making a personal copy of someone else’s file or project. When you fork a file, you create your own version of it that you can modify and make changes to without affecting the original file.\nHere’s a simple analogy: Imagine you have a friend who has a really cool drawing. You want to add your own touches and modifications to that drawing, but you don’t want to mess up your friend’s original. So, what you do is make a photocopy of the drawing and work on that copy. This way, you can freely experiment and make changes without worrying about ruining the original.\nIn GitHub, forking is similar. If you find a file or project in someone else’s repository that you want to modify or contribute to, you can fork it to create your own personal copy of that repository. This copy will be stored in your GitHub account, and you can make changes without affecting the original file or the owner’s repository.\nOnce you’ve made the desired changes to your forked repository, you can choose to share those changes with the original owner through a process called a pull request. This allows the owner to review your changes and decide whether to incorporate them into the original file or project.\n\n\nHow to fork a file on Github?\nTo fork a repository in GitHub, including all its files, branches, and commit history, follow these steps:\n\nOpen your web browser and go to the GitHub repository page that contains the file you want to fork.\nIn the top-right corner of the repository page, click on the “Fork” button.\nGitHub will prompt you to select where you want to fork the repository. Choose your user account or any organization you belong to. Click on the appropriate option.\nGitHub will then create a copy of the repository under your account or organization. Once the forking process is complete, you will be redirected to the forked repository’s page.\n\nNow you have successfully forked the entire repository, not just an individual file. You will have a separate copy of the repository in your GitHub account. This copy will include all the files, branches, and commit history present in the original repository.\nYou can make changes to the files, add new features, fix bugs, or experiment with the forked repository as you see fit. You can commit and push changes to the forked repository without affecting the original repository"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Large Language Models in Molecular Biology",
    "section": "",
    "text": "Practicing Working with Terminal\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\nSrusti Donapati\n\n\n\n\n\n\n  \n\n\n\n\nThe Biology to be Explored in LLMs\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\nSrusti Donapati\n\n\n\n\n\n\n  \n\n\n\n\nBasics of LLMs and Their Role in the Field of Biology\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\nSrusti Donapati\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My ‘LLM in Biology’ Blog!\n\n\n\n\n\n\n\nblog\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2023\n\n\nSrusti Donapati\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is essentially a project of progress reports on biological knowledge and computational skills that I have acquired over my 8 weeks in the Im Lab during Summer 2023 for the GPT in Genomics Project."
  }
]